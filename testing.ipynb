{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3320c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSD_MobileNetV3_ADIS'...\n",
      "remote: Enumerating objects: 187, done.\u001b[K\n",
      "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
      "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
      "remote: Total 187 (delta 113), reused 116 (delta 50), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (187/187), 24.96 MiB | 42.60 MiB/s, done.\n",
      "Resolving deltas: 100% (113/113), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.0.1\n",
      "Collecting ultralytics (from -r requirements.txt (line 1))\n",
      "  Downloading ultralytics-8.3.110-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting albumentations==2.0.5 (from -r requirements.txt (line 2))\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: optuna==4.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.30.2)\n",
      "Collecting lmdb==1.6.2 (from -r requirements.txt (line 5))\n",
      "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: torchmetrics==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.7.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (1.15.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (2.11.3)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (4.11.0.86)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (2.0.38)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (4.13.1)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.3.8)\n",
      "Collecting mkl_fft (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_fft-1.3.14-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.2.4)\n",
      "Collecting mkl_random (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (0.1.1)\n",
      "Collecting mkl_umath (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2.4.1)\n",
      "Collecting mkl-service (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.5.1+cu124)\n",
      "Collecting torch>=2.0.0 (from torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (0.14.3)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (3.11.3)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2))\n",
      "  Downloading stringzilla-3.12.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (6.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (3.7.5)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (11.1.0)\n",
      "Collecting pillow>=7.1.2 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.20.1+cu124)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.12.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3)) (1.3.9)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (75.1.0)\n",
      "Collecting setuptools (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.3.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (4.56.0)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (3.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.3.0)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 3)) (3.1.1)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-openmp<2026,>=2024 (from mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_openmp-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8)) (1.2.0)\n",
      "Collecting tcmlib==1.* (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading tcmlib-1.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (964 bytes)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-cmplr-lib-rt (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_rt-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting intel-cmplr-lib-ur==2025.1.0 (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_ur-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting umf==0.10.* (from intel-cmplr-lib-ur==2025.1.0->intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading umf-0.10.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.0.2)\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\n",
      "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
      "Downloading ultralytics-8.3.110-py3-none-any.whl (978 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.8/978.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m137.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m158.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m117.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Downloading tcmlib-1.3.0-py2.py3-none-manylinux_2_28_x86_64.whl (4.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_fft-1.3.14-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl (77 kB)\n",
      "Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl (441 kB)\n",
      "Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading intel_openmp-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (48.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading intel_cmplr_lib_ur-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading umf-0.10.0-py2.py3-none-manylinux_2_28_x86_64.whl (314 kB)\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Downloading stringzilla-3.12.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading intel_cmplr_lib_rt-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl (47.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Downloading setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, tcmlib, stringzilla, nvidia-cusparselt-cu12, lmdb, intel-cmplr-lib-rt, urllib3, umf, typing-extensions, setuptools, pyparsing, pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, Mako, greenlet, fonttools, sqlalchemy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, intel-cmplr-lib-ur, nvidia-cusolver-cu12, intel-openmp, torch, mkl-service, mkl_umath, mkl_random, mkl_fft, contourpy, matplotlib, ultralytics-thop, torchvision, seaborn, ultralytics, albumentations\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.1.0\n",
      "    Uninstalling triton-3.1.0:\n",
      "      Successfully uninstalled triton-3.1.0\n",
      "  Attempting uninstall: tcmlib\n",
      "    Found existing installation: tcmlib 1.2.0\n",
      "    Uninstalling tcmlib-1.2.0:\n",
      "      Successfully uninstalled tcmlib-1.2.0\n",
      "  Attempting uninstall: stringzilla\n",
      "    Found existing installation: stringzilla 3.11.3\n",
      "    Uninstalling stringzilla-3.11.3:\n",
      "      Successfully uninstalled stringzilla-3.11.3\n",
      "  Attempting uninstall: intel-cmplr-lib-rt\n",
      "    Found existing installation: intel-cmplr-lib-rt 2024.2.0\n",
      "    Uninstalling intel-cmplr-lib-rt-2024.2.0:\n",
      "      Successfully uninstalled intel-cmplr-lib-rt-2024.2.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "  Attempting uninstall: umf\n",
      "    Found existing installation: umf 0.9.1\n",
      "    Uninstalling umf-0.9.1:\n",
      "      Successfully uninstalled umf-0.9.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.13.1\n",
      "    Uninstalling typing_extensions-4.13.1:\n",
      "      Successfully uninstalled typing_extensions-4.13.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.1\n",
      "    Uninstalling pyparsing-3.2.1:\n",
      "      Successfully uninstalled pyparsing-3.2.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: Mako\n",
      "    Found existing installation: Mako 1.3.9\n",
      "    Uninstalling Mako-1.3.9:\n",
      "      Successfully uninstalled Mako-1.3.9\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.1.1\n",
      "    Uninstalling greenlet-3.1.1:\n",
      "      Successfully uninstalled greenlet-3.1.1\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.56.0\n",
      "    Uninstalling fonttools-4.56.0:\n",
      "      Successfully uninstalled fonttools-4.56.0\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.38\n",
      "    Uninstalling SQLAlchemy-2.0.38:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.38\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: intel-cmplr-lib-ur\n",
      "    Found existing installation: intel-cmplr-lib-ur 2024.2.0\n",
      "    Uninstalling intel-cmplr-lib-ur-2024.2.0:\n",
      "      Successfully uninstalled intel-cmplr-lib-ur-2024.2.0\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: intel-openmp\n",
      "    Found existing installation: intel-openmp 2024.2.0\n",
      "    Uninstalling intel-openmp-2024.2.0:\n",
      "      Successfully uninstalled intel-openmp-2024.2.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu124\n",
      "    Uninstalling torch-2.5.1+cu124:\n",
      "      Successfully uninstalled torch-2.5.1+cu124\n",
      "  Attempting uninstall: mkl-service\n",
      "    Found existing installation: mkl-service 2.4.1\n",
      "    Uninstalling mkl-service-2.4.1:\n",
      "      Successfully uninstalled mkl-service-2.4.1\n",
      "  Attempting uninstall: mkl_umath\n",
      "    Found existing installation: mkl-umath 0.1.1\n",
      "    Uninstalling mkl-umath-0.1.1:\n",
      "      Successfully uninstalled mkl-umath-0.1.1\n",
      "  Attempting uninstall: mkl_random\n",
      "    Found existing installation: mkl-random 1.2.4\n",
      "    Uninstalling mkl-random-1.2.4:\n",
      "      Successfully uninstalled mkl-random-1.2.4\n",
      "  Attempting uninstall: mkl_fft\n",
      "    Found existing installation: mkl-fft 1.3.8\n",
      "    Uninstalling mkl-fft-1.3.8:\n",
      "      Successfully uninstalled mkl-fft-1.3.8\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.3.1\n",
      "    Uninstalling contourpy-1.3.1:\n",
      "      Successfully uninstalled contourpy-1.3.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.7.5\n",
      "    Uninstalling matplotlib-3.7.5:\n",
      "      Successfully uninstalled matplotlib-3.7.5\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu124\n",
      "    Uninstalling torchvision-0.20.1+cu124:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu124\n",
      "  Attempting uninstall: seaborn\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 2.0.4\n",
      "    Uninstalling albumentations-2.0.4:\n",
      "      Successfully uninstalled albumentations-2.0.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\n",
      "datasets 3.5.0 requires fsspec[http]<=2024.12.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "ydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, but you have matplotlib 3.10.1 which is incompatible.\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "google-spark-connect 0.5.2 requires google-api-core>=2.19.1, but you have google-api-core 1.34.1 which is incompatible.\n",
      "pandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 44.0.2 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.0.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "ibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
      "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\n",
      "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\n",
      "google-cloud-bigtable 2.28.1 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.10 albumentations-2.0.5 contourpy-1.3.2 fonttools-4.57.0 greenlet-3.2.0 intel-cmplr-lib-rt-2025.1.0 intel-cmplr-lib-ur-2025.1.0 intel-openmp-2025.1.0 lmdb-1.6.2 matplotlib-3.10.1 mkl-service-2.4.2 mkl_fft-1.3.14 mkl_random-1.2.10 mkl_umath-0.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nvjitlink-cu12-12.4.127 pillow-11.2.1 pyparsing-3.2.3 seaborn-0.13.2 setuptools-78.1.0 sqlalchemy-2.0.40 stringzilla-3.12.4 tcmlib-1.3.0 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 typing-extensions-4.13.2 ultralytics-8.3.110 ultralytics-thop-2.0.14 umf-0.10.0 urllib3-2.4.0\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu126\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.14)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.10)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.5)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2025.1.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2025.1.0)\n",
      "Requirement already satisfied: umf==0.10.* in /usr/local/lib/python3.11/dist-packages (from intel-cmplr-lib-ur==2025.1.0->intel-openmp<2026,>=2024->mkl->numpy->torchvision) (0.10.0)\n",
      "Downloading https://download.pytorch.org/whl/cu126/torchaudio-2.6.0%2Bcu126-cp311-cp311-linux_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.5.1+cu124\n",
      "    Uninstalling torchaudio-2.5.1+cu124:\n",
      "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
      "Successfully installed torchaudio-2.6.0+cu126\n"
     ]
    }
   ],
   "source": [
    "# clone the ADIS repository\n",
    "!git clone https://github.com/sathishkumar67/SSD_MobileNetV3_ADIS.git\n",
    "# move the files to the current directory\n",
    "!mv /kaggle/working/SSD_MobileNetV3_ADIS/* /kaggle/working/\n",
    "# upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# install the required packages\n",
    "!pip install  -r requirements.txt --upgrade --upgrade-strategy eager\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import optuna\n",
    "import joblib\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from ssd_mobnetv3_adis import unzip_file\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from ssd_mobnetv3_adis import collate_fn, SSDLITEOBJDET_DATASET, CachedSSDLITEOBJDET_DATASET, SSD_MOBILENET_V3_Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd607711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90215d78951f42888c8fe3da7ccf2842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "balanced_dataset.zip:   0%|          | 0.00/7.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|██████████| 7.07G/7.07G [00:42<00:00, 166MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped /kaggle/working/balanced_dataset.zip to /kaggle/working\n",
      "Removed zip file: /kaggle/working/balanced_dataset.zip\n",
      "Number of CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "# set constants\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"                       \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "NUM_CLASSES = len(CLASSES)\n",
    "MODEL_NUM_CLASSES = NUM_CLASSES + 1    # 1 for background class\n",
    "\n",
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)\n",
    "\n",
    "# number of cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db86b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/train_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9540/18139 [02:05<05:09, 27.82it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 18139/18139 [03:40<00:00, 82.12it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/val_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2390/2390 [00:26<00:00, 88.72it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/test_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1747/2390 [00:21<00:04, 151.17it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 2390/2390 [00:28<00:00, 83.07it/s] \n"
     ]
    }
   ],
   "source": [
    "# set pin memory device\n",
    "PIN_MEMORY_DEVICE = \"cuda:0\"\n",
    "\n",
    "# prepare the dataset\n",
    "train_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"train\",\n",
    "    num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"val\",\n",
    "    num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"test\",\n",
    "    num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "\n",
    "# samplers for reproducibility\n",
    "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(42))\n",
    "val_sampler = RandomSampler(val_dataset, generator=torch.Generator().manual_seed(42))\n",
    "test_sampler = RandomSampler(test_dataset, generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "# prepare the dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    sampler=test_sampler,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "227b57c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD_MOBILENET_V3_Large(\n",
       "  (model): SSD(\n",
       "    (backbone): SSDLiteFeatureExtractorMobileNet(\n",
       "      (features): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "                (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (6): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "                (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (7): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "                (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (8): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "                (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (9): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (10): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "                (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): Conv2dNormActivation(\n",
       "                (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (11): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (12): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "                (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (13): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Sequential(\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (block): Sequential(\n",
       "              (0): Conv2dNormActivation(\n",
       "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (1): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "                (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (2): Hardswish()\n",
       "              )\n",
       "              (2): SqueezeExcitation(\n",
       "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "                (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (activation): ReLU()\n",
       "                (scale_activation): Hardsigmoid()\n",
       "              )\n",
       "              (3): Conv2dNormActivation(\n",
       "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (extra): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], clip=True, scales=[0.2, 0.35, 0.5, 0.65, 0.8, 0.95, 1.0], steps=None)\n",
       "    (head): SSDLiteHead(\n",
       "      (classification_head): SSDLiteClassificationHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=1e-08, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=1e-08, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-08, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-08, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=1e-08, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 66, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (regression_head): SSDLiteRegressionHead(\n",
       "        (module_list): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(672, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(480, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (3-4): 2 x Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (5): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU6(inplace=True)\n",
       "            )\n",
       "            (1): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transform): GeneralizedRCNNTransform(\n",
       "        Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "        Resize(min_size=(320,), max_size=320, mode='bilinear')\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\", map_location=\"cpu\")[\"model_state_dict\"], strict=False)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a458f7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = MeanAveragePrecision(\n",
    "        iou_type=\"bbox\",\n",
    "        class_metrics=True,\n",
    "        extended_summary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "320b7a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 19/19 [00:18<00:00,  1.03batch/s]\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(val_loader, desc=\"Evaluating\", unit=\"batch\", total=len(val_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, targets in progress_bar:\n",
    "        images = images.to(device)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        predictions = model(images)\n",
    "        metric.update(predictions, targets)\n",
    "    map_results = metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae60911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(warmup_epochs: int, num_epochs: int, patience: int, initial_lr: float, betas: Tuple[float, float], weight_decay: float, dataloaders: dict[str, torch.utils.data.DataLoader]) -> None:\n",
    "#     # early stopping parameters\n",
    "#     best_map = float('-inf')\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     # get the dataloaders\n",
    "#     train_loader, val_loader = dataloaders['train'], dataloaders['val']\n",
    "    \n",
    "#     # Set device\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Load the model\n",
    "#     model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer\n",
    "#     optimizer = model.configure_optimizers(lr=initial_lr, betas=betas, weight_decay=weight_decay, eps=1e-08, fused=True)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Warmup phase: linearly increase learning rate for the first 4 epochs\n",
    "#         if epoch < warmup_epochs:\n",
    "#             lr = initial_lr * (epoch + 1) / warmup_epochs\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr'] = lr\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         num_batches = len(train_loader)\n",
    "        \n",
    "#         # Progress bar\n",
    "#         train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "#         for _, (images, targets) in enumerate(train_bar):\n",
    "#             # Move data to device\n",
    "#             images = images.to(device)\n",
    "#             targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#             # Forward pass\n",
    "#             loss_dict = model(images, targets)\n",
    "#             losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             losses.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             batch_loss = losses.detach().item()\n",
    "#             total_loss += batch_loss\n",
    "            \n",
    "#             # Update progress bar\n",
    "#             train_bar.set_postfix(loss=batch_loss)\n",
    "        \n",
    "#         avg_loss = total_loss / num_batches\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs} | Learning Rate: {lr:.6f} | Avg Train Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         metric = MeanAveragePrecision()\n",
    "#         eval_bar = tqdm(val_loader, desc=f\"Validating...\", unit=\"batch\")\n",
    "#         with torch.no_grad():\n",
    "#             for images, targets in eval_bar:\n",
    "#                 # Move data to device\n",
    "#                 images = images.to(device)\n",
    "#                 targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#                 # Forward pass    \n",
    "#                 predictions = model(images)\n",
    "#                 metric.update(predictions, targets)\n",
    "        \n",
    "#         map_result = metric.compute()\n",
    "#         print(f\"Epoch {epoch+1} | Val mAP: {map_result['map']:.4f}\")\n",
    "        \n",
    "#         # Early stopping logic\n",
    "#         if map_result['map'] > best_map:\n",
    "#             best_map = map_result['map']\n",
    "#             best_model_state_dict = {k: v.cpu() for k, v in model.state_dict().items()} \n",
    "#             best_optimizer_state_dict = optimizer.state_dict()\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(\"Early stopping triggered at epoch\", epoch + 1)\n",
    "#                 # save the best model\n",
    "#                 torch.save({\"model_state_dict\" : best_model_state_dict,\n",
    "#                     \"optimizer_state_dict\" : best_optimizer_state_dict,\n",
    "#                 }, f\"{LOCAL_DIR}/best_model.pth\")\n",
    "#                 print(f\"Best model saved with mAP: {best_map:.4f}\")\n",
    "#                 break\n",
    "\n",
    "# # train the model with the suggested hyperparameters\n",
    "# train(warmup_epochs=4, num_epochs=50, patience=5, initial_lr=0.0001, betas=(0.9, 0.999), weight_decay=0.001, dataloaders={'train': train_loader, 'val': val_loader})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # bohb tuning parameters\n",
    "# def train(warmup_epochs: int, num_epochs: int, patience: int, initial_lr: float, betas: Tuple[float, float], weight_decay: float, dataloaders: dict[str, torch.utils.data.DataLoader], callback):\n",
    "#     # early stopping parameters\n",
    "#     best_map = float('-inf')\n",
    "#     patience_counter = 0\n",
    "    \n",
    "#     # get the dataloaders\n",
    "#     train_loader, val_loader = dataloaders['train'], dataloaders['val']\n",
    "    \n",
    "#     # Set device\n",
    "#     device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#     print(f\"Using device: {device}\")\n",
    "    \n",
    "#     # Load the model\n",
    "#     model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Optimizer\n",
    "#     optimizer = model.configure_optimizers(lr=initial_lr, betas=betas, weight_decay=weight_decay, eps=1e-08, fused=True)\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         # Warmup phase: linearly increase learning rate for the first 4 epochs\n",
    "#         if epoch < warmup_epochs:\n",
    "#             lr = initial_lr * (epoch + 1) / warmup_epochs\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr'] = lr\n",
    "#         # Training phase\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         num_batches = len(train_loader)\n",
    "        \n",
    "#         # Progress bar\n",
    "#         train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "#         for _, (images, targets) in enumerate(train_bar):\n",
    "#             # Move data to device\n",
    "#             images = images.to(device)\n",
    "#             targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#             # Forward pass\n",
    "#             loss_dict = model(images, targets)\n",
    "#             losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             losses.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             batch_loss = losses.detach().item()\n",
    "#             total_loss += batch_loss\n",
    "            \n",
    "#             # Update progress bar\n",
    "#             train_bar.set_postfix(loss=batch_loss)\n",
    "        \n",
    "#         avg_loss = total_loss / num_batches\n",
    "#         print(f\"Epoch {epoch+1}/{num_epochs} | Learning Rate: {lr:.6f} | Avg Train Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "#         # Validation phase\n",
    "#         model.eval()\n",
    "#         metric = MeanAveragePrecision()\n",
    "#         eval_bar = tqdm(val_loader, desc=f\"Validating...\", unit=\"batch\")\n",
    "#         with torch.no_grad():\n",
    "#             for images, targets in eval_bar:\n",
    "#                 # Move data to device\n",
    "#                 images = images.to(device)\n",
    "#                 targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "#                 # Forward pass    \n",
    "#                 predictions = model(images)\n",
    "#                 metric.update(predictions, targets)\n",
    "        \n",
    "#         map_result = metric.compute()\n",
    "#         print(f\"Epoch {epoch+1} | Val mAP: {map_result['map']:.4f}\")\n",
    "        \n",
    "#         # Report the validation mAP\n",
    "#         callback(map_result['map'], epoch+1)\n",
    "        \n",
    "#         # Early stopping logic\n",
    "#         if map_result['map'] > best_map:\n",
    "#             best_map = map_result['map']\n",
    "#             patience_counter = 0\n",
    "#         else:\n",
    "#             patience_counter += 1\n",
    "#             if patience_counter >= patience:\n",
    "#                 print(\"Early stopping triggered at epoch\", epoch + 1)\n",
    "#                 break\n",
    "            \n",
    "#     return best_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # constants\n",
    "# WARMUP_EPOCHS = 3\n",
    "# NUM_EPOCHS = 15\n",
    "# PATIENCE = 3\n",
    "\n",
    "# # define the dataloaders\n",
    "# dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
    "\n",
    "# # define the objective function\n",
    "# def objective(trial):\n",
    "#     # define callback to report intermidiate results\n",
    "#     def on_train_epoch_end(score, epoch):\n",
    "#         trial.report(score, step=epoch)  \n",
    "#         if trial.should_prune():\n",
    "#             raise optuna.TrialPruned()\n",
    "        \n",
    "#     # suggest hyperparameters for the model\n",
    "#     lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "#     weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "#     momentum = trial.suggest_float(\"momentum\", 0.7, 0.99)\n",
    "    \n",
    "#     # train the model\n",
    "#     best_map = train(warmup_epochs=WARMUP_EPOCHS, num_epochs=NUM_EPOCHS, patience=PATIENCE, initial_lr=lr, betas=(momentum, 0.999), weight_decay=weight_decay,\n",
    "#         dataloaders=dataloaders, callback=on_train_epoch_end)\n",
    "    \n",
    "#     # return the best mAP\n",
    "#     return best_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b10571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the number of trials\n",
    "# NUM_TRIALS = 5\n",
    "\n",
    "# # load the study\n",
    "# study = optuna.create_study(direction='maximize', \n",
    "#                             sampler=optuna.samplers.TPESampler(), \n",
    "#                             pruner=optuna.pruners.HyperbandPruner(),\n",
    "#                             study_name=\"ssd_mobnetv3_adis_tuning\",\n",
    "#                             load_if_exists=True)\n",
    "\n",
    "# # Optimize with a callback to stop after NUM_TRIALS complete trials\n",
    "# study.optimize(objective, n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500347e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(study, f\"{LOCAL_DIR}/optuna_study.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
