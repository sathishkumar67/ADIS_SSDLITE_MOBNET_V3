{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3320c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSD_MobileNetV3_ADIS'...\n",
      "remote: Enumerating objects: 173, done.\u001b[K\n",
      "remote: Counting objects: 100% (173/173), done.\u001b[K\n",
      "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
      "remote: Total 173 (delta 104), reused 107 (delta 46), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (173/173), 74.96 KiB | 5.35 MiB/s, done.\n",
      "Resolving deltas: 100% (104/104), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.0.1\n",
      "Collecting ultralytics (from -r requirements.txt (line 1))\n",
      "  Downloading ultralytics-8.3.109-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting albumentations==2.0.5 (from -r requirements.txt (line 2))\n",
      "  Downloading albumentations-2.0.5-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: optuna==4.2.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: huggingface-hub==0.30.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.30.2)\n",
      "Collecting lmdb==1.6.2 (from -r requirements.txt (line 5))\n",
      "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: torchmetrics==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.7.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (1.15.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (2.11.3)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 2)) (4.11.0.86)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 3)) (2.0.38)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 4)) (4.13.1)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.3.8)\n",
      "Collecting mkl_fft (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_fft-1.3.14-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (1.2.4)\n",
      "Collecting mkl_random (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (0.1.1)\n",
      "Collecting mkl_umath (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 8)) (2.4.1)\n",
      "Collecting mkl-service (from numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.5.1+cu124)\n",
      "Collecting torch>=2.0.0 (from torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 9)) (0.14.3)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (3.11.3)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2))\n",
      "  Downloading stringzilla-3.12.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 2)) (6.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (3.7.5)\n",
      "Collecting matplotlib>=3.3.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (11.1.0)\n",
      "Collecting pillow>=7.1.2 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.20.1+cu124)\n",
      "Collecting torchvision>=0.9.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 1)) (0.12.2)\n",
      "Collecting seaborn>=0.11.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3)) (1.3.9)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (75.1.0)\n",
      "Collecting setuptools (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.3.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading contourpy-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (4.56.0)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading fonttools-4.57.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (102 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (3.2.1)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 2)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2.3.0)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4))\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 3)) (3.1.1)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 3))\n",
      "  Downloading greenlet-3.2.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9))\n",
      "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-openmp<2026,>=2024 (from mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_openmp-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 8)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8)) (1.2.0)\n",
      "Collecting tcmlib==1.* (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading tcmlib-1.3.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (964 bytes)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8)) (2024.2.0)\n",
      "Collecting intel-cmplr-lib-rt (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_rt-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting intel-cmplr-lib-ur==2025.1.0 (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading intel_cmplr_lib_ur-2025.1.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting umf==0.10.* (from intel-cmplr-lib-ur==2025.1.0->intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 8))\n",
      "  Downloading umf-0.10.0-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics==1.7.1->-r requirements.txt (line 9)) (3.0.2)\n",
      "Downloading albumentations-2.0.5-py3-none-any.whl (290 kB)\n",
      "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
      "Downloading ultralytics-8.3.109-py3-none-any.whl (974 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.8/974.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m129.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m664.5/664.8 MB\u001b[0m \u001b[31m267.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m00:01\u001b[0m"
     ]
    }
   ],
   "source": [
    "# clone the ADIS repository\n",
    "!git clone https://github.com/sathishkumar67/SSD_MobileNetV3_ADIS.git\n",
    "!mv /kaggle/working/SSD_MobileNetV3_ADIS/* /kaggle/working/\n",
    "!pip install --upgrade pip\n",
    "# install the required packages\n",
    "!pip install  -r requirements.txt --upgrade --upgrade-strategy eager\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import torch\n",
    "import optuna\n",
    "import joblib\n",
    "from typing import Tuple\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from ssd_mobnetv3_adis import unzip_file\n",
    "from huggingface_hub import hf_hub_download\n",
    "from torch.utils.data import DataLoader\n",
    "from ssd_mobnetv3_adis import collate_fn, SSDLITEOBJDET_DATASET, CachedSSDLITEOBJDET_DATASET, SSD_MOBILENET_V3_Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd607711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af3c663ea314a8bad66edb90437c6e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "balanced_dataset.zip:   0%|          | 0.00/7.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping: 100%|██████████| 7.07G/7.07G [00:42<00:00, 167MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipped /kaggle/working/balanced_dataset.zip to /kaggle/working\n",
      "Removed zip file: /kaggle/working/balanced_dataset.zip\n",
      "Number of CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "# set constants\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"                       \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "NUM_CLASSES = len(CLASSES)                        \n",
    "BACKGROUND_CLASS_ID = 0\n",
    "MODEL_NUM_CLASSES = NUM_CLASSES + 1    # 1 for background class\n",
    "\n",
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)\n",
    "\n",
    "# number of cores\n",
    "num_cores = os.cpu_count()\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4db86b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/train_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9534/18139 [02:05<06:39, 21.56it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 18139/18139 [03:39<00:00, 82.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/val_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2390/2390 [00:26<00:00, 88.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/test_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1744/2390 [00:21<00:04, 159.79it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 2390/2390 [00:28<00:00, 84.03it/s] \n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "train_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"train\",\n",
    "    num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"val\",\n",
    "    num_classes=MODEL_NUM_CLASSES)\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"test\",\n",
    "    num_classes=MODEL_NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb46558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=\"cuda:0\")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=\"cuda:0\")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=num_cores,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01adf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(warmup_epochs: int, num_epochs: int, patience: int, initial_lr: float, betas: Tuple[float, float], weight_decay: float, dataloaders: dict[str, torch.utils.data.DataLoader], callback) -> None:\n",
    "    # early stopping parameters\n",
    "    best_map = float('-inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # get the dataloaders\n",
    "    train_loader, val_loader = dataloaders['train'], dataloaders['val']\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load the model\n",
    "    model = SSD_MOBILENET_V3_Large(num_classes_with_bg=MODEL_NUM_CLASSES)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = model.configure_optimizers(lr=initial_lr, betas=betas, weight_decay=weight_decay, eps=1e-08, fused=True)\n",
    "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Warmup phase: linearly increase learning rate for the first 4 epochs\n",
    "        if epoch < warmup_epochs:\n",
    "            lr = initial_lr * (epoch + 1) / warmup_epochs\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(train_loader)\n",
    "        \n",
    "        # Progress bar\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        \n",
    "        for _, (images, targets) in enumerate(train_bar):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_loss = losses.detach().item()\n",
    "            total_loss += batch_loss\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_bar.set_postfix(loss=batch_loss)\n",
    "        \n",
    "        avg_loss = total_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Learning Rate: {lr:.6f} | Avg Train Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        metric = MeanAveragePrecision()\n",
    "        eval_bar = tqdm(val_loader, desc=f\"Validating...\", unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for images, targets in eval_bar:\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "                # Forward pass    \n",
    "                predictions = model(images)\n",
    "                metric.update(predictions, targets)\n",
    "        \n",
    "        map_result = metric.compute()\n",
    "        print(f\"Epoch {epoch+1} | Val mAP: {map_result['map']:.4f}\")\n",
    "        \n",
    "        # Report the validation mAP\n",
    "        callback(map_result['map'], epoch+1)\n",
    "        \n",
    "        # Early stopping logic\n",
    "        if map_result['map'] > best_map:\n",
    "            best_map = map_result['map']\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered at epoch\", epoch + 1)\n",
    "                break\n",
    "        \n",
    "        # Step the learning rate scheduler after warmup\n",
    "        if epoch >= warmup_epochs:\n",
    "            lr_scheduler.step()\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "    print(f\"Best mAP: {best_map:.4f}\")\n",
    "    return best_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eb9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\"train\":train_loader, \"val\":val_loader}\n",
    "\n",
    "def objective(trial):\n",
    "    # define callback to report intermidiate results\n",
    "    def on_train_epoch_end(score, epoch):\n",
    "        trial.report(score, step=epoch)  \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True)\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.7, 0.99)\n",
    "    \n",
    "    best_map = train(warmup_epochs=4, num_epochs=10, patience=4, initial_lr=lr, betas=(momentum, 0.999), weight_decay=weight_decay,\n",
    "        dataloaders=dataloaders, callback=on_train_epoch_end)\n",
    "    return best_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b10571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-17 04:26:54,295] A new study created in memory with name: ssd_mobnetv3_adis_tuning\n"
     ]
    }
   ],
   "source": [
    "NUM_TRIALS = 5\n",
    "\n",
    "# load the study\n",
    "study = optuna.create_study(direction='maximize', \n",
    "                            sampler=optuna.samplers.TPESampler(), \n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            study_name=\"ssd_mobnetv3_adis_tuning\",\n",
    "                            load_if_exists=True)\n",
    "\n",
    "# Optimize with a callback to stop after NUM_TRIALS complete trials\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500347e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  87%|████████▋ | 124/142 [01:51<00:16,  1.11batch/s, loss=5.95]\n",
      "[W 2025-04-17 04:29:02,629] Trial 1 failed with parameters: {'lr': 0.0003258226447882577, 'weight_decay': 7.351008945883096e-05, 'momentum': 0.8069944975912936} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_71/1982897661.py\", line 14, in objective\n",
      "    best_map = train(warmup_epochs=4, num_epochs=10, patience=4, initial_lr=lr, betas=(momentum, 0.999), weight_decay=weight_decay,\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_71/27229307.py\", line 40, in train\n",
      "    loss_dict = model(images, targets)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/kaggle/working/ssd_mobnetv3_adis/model.py\", line 88, in forward\n",
      "    return self.model(images, targets)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/ssd.py\", line 400, in forward\n",
      "    matched_idxs.append(self.proposal_matcher(match_quality_matrix))\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/_utils.py\", line 428, in __call__\n",
      "    _, highest_quality_pred_foreach_gt = match_quality_matrix.max(dim=1)\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-17 04:29:02,644] Trial 1 failed with value None.\n",
      "Exception in thread Thread-79 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 59, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 35, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/torch/multiprocessing/reductions.py\", line 541, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "         ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 519, in Client\n",
      "    c = SocketClient(address)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/connection.py\", line 647, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_71/1515200559.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optimize with a callback to stop after NUM_TRIALS complete trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m study.optimize(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     n_trials=NUM_TRIALS)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_71/1982897661.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmomentum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     best_map = train(warmup_epochs=4, num_epochs=10, patience=4, initial_lr=lr, betas=(momentum, 0.999), weight_decay=weight_decay,\n\u001b[0m\u001b[1;32m     15\u001b[0m         dataloaders=dataloaders, callback=on_train_epoch_end)\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_71/27229307.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(warmup_epochs, num_epochs, patience, initial_lr, betas, weight_decay, dataloaders, callback)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kaggle/working/ssd_mobnetv3_adis/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m \u001b[0moutput\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                     \u001b[0mmatch_quality_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbox_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_iou\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets_per_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"boxes\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors_per_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                     \u001b[0mmatched_idxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproposal_matcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch_quality_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatched_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/models/detection/_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, match_quality_matrix)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;31m# For each gt, find the prediction with which it has the highest quality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhighest_quality_pred_foreach_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_quality_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         matches[highest_quality_pred_foreach_gt] = torch.arange(\n\u001b[1;32m    430\u001b[0m             \u001b[0mhighest_quality_pred_foreach_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhighest_quality_pred_foreach_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "joblib.dump(study, f\"{LOCAL_DIR}/optuna_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Saving the model...\")\n",
    "\n",
    "# # Save the model\n",
    "# torch.save({\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict()\n",
    "# }, 'ssd_mobilenet_v3_finetuned.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
