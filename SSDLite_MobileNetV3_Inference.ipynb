{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e84b4dd",
   "metadata": {},
   "source": [
    "# SSDLite + MobileNetV3 — Inference and Evaluation\n",
    "This notebook loads trained SSDLite+MobileNetV3 checkpoints, prepares the\n",
    "validation/test dataloaders, and runs evaluation/visualization helpers (PR\n",
    "curves, confusion matrix, per-class metrics).\n",
    "\n",
    "Notes:\n",
    "- Helpful helper modules are available in `ssdlite_mobnetv3_adis` (dataset,\n",
    "  model, plot, evaluate, trainer, utils).\n",
    "- The cells below perform only inference and evaluation — no training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3320c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the ADIS repository\n",
    "!git clone https://github.com/sathishkumar67/SSD_MobileNetV3_ADIS.git\n",
    "# move the files to the current directory\n",
    "!mv /kaggle/working/SSD_MobileNetV3_ADIS/* /kaggle/working/ # move the files to the current directory\n",
    "# upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# install the required packages\n",
    "!pip install  -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook imports and reproducibility settings\n",
    "# This cell imports required libraries and project modules used for inference\n",
    "# Keep imports minimal here; heavy work is delegated to `ssdlite_mobnetv3_adis` helpers\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torchvision import transforms\n",
    "from ssdlite_mobnetv3_adis.dataset import collate_fn, SSDLITEOBJDET_DATASET, CachedSSDLITEOBJDET_DATASET\n",
    "from ssdlite_mobnetv3_adis.model import SSDLITE_MOBILENET_V3_Large\n",
    "from ssdlite_mobnetv3_adis.utils import unzip_file\n",
    "from ssdlite_mobnetv3_adis.inference import draw_detections\n",
    "\n",
    "# Set random seed for reproducibility (affects dataset sampling, torch, numpy, etc.)\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd607711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset / repository constants and download helper\n",
    "# Update REPO_ID / DATASET_NAME if you have a different dataset or hub location\n",
    "REPO_ID = \"pt-sk/ADIS\"\n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"\n",
    "\n",
    "# Class list and counts (CLASSES excludes background; NUM_CLASSES_WITH_BG adds background)\n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "NUM_CLASSES_WITH_BG = NUM_CLASSES + 1    # 1 for background class\n",
    "\n",
    "# Download the dataset from the Hub and unzip it locally (idempotent if already present)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db86b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader construction and caching notes\n",
    "# This cell prepares cached dataset wrappers and DataLoaders used for train/val/test\n",
    "# BATCH_SIZE, PIN_MEMORY_DEVICE and num_workers are tuned for your environment\n",
    "PIN_MEMORY_DEVICE = \"cuda:0\"\n",
    "NUM_CORES = os.cpu_count()\n",
    "BATCH_SIZE = 64 # Adjust based on your system's memory capacity\n",
    "\n",
    "# Prepare dataset objects (uses CachedSSDLITEOBJDET_DATASET which creates/reads an LMDB cache)\n",
    "train_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"train\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"val\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"test\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "# Use RandomSampler with fixed generator for reproducible shuffling across runs\n",
    "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "val_sampler = RandomSampler(val_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "test_sampler = RandomSampler(test_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "# Create DataLoaders — collate_fn converts numpy HWC images to CHW tensors and packs targets\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=test_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abbd0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device selection and model checkpoint loading\n",
    "# Choose device (GPU if available) — ensure your environment has CUDA configured if using GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Path to saved checkpoint (update this if your checkpoint lives elsewhere)\n",
    "best_ckpt_path = \"\"\n",
    "best_ckpt = torch.load(best_ckpt_path, map_location=\"cpu\")\n",
    "\n",
    "# Build the model with the correct number of classes (includes background)\n",
    "best_model = SSDLITE_MOBILENET_V3_Large(num_classes_with_bg=NUM_CLASSES_WITH_BG)\n",
    "best_model.load_state_dict(best_ckpt['model_state_dict'], strict=True)\n",
    "best_model.to(device)\n",
    "best_model.eval()\n",
    "# Model is now ready for inference\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "from ssdlite_mobnetv3_adis.evaluate import compute_average_metrics\n",
    "eval_metrics = compute_average_metrics(\n",
    "    best_model,\n",
    "    val_loader, # use val_loader or test_loader or any other dataloader as needed\n",
    "    device,\n",
    "    CLASSES,\n",
    ")\n",
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the image path for inference\n",
    "image_path = \"\"\n",
    "# load that image and convert to torch tensor with image size (320, 320)\n",
    "image = Image.open(image_path)\n",
    "image = transforms.Resize((320, 320))(image)\n",
    "image = transforms.ToTensor()(image)\n",
    "image = torch.unsqueeze(image, 0)\n",
    "image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180eedf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw detections on the image\n",
    "draw_detections(\n",
    "    image_or_path=image_path,\n",
    "    model=best_model,\n",
    "    device=device,\n",
    "    classes=CLASSES,\n",
    "    conf_thresh=0.07,\n",
    "    input_size=320,\n",
    "    show=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
