{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d3320c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSD_MobileNetV3_ADIS'...\n",
      "remote: Enumerating objects: 303, done.\u001b[K\n",
      "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
      "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
      "remote: Total 303 (delta 38), reused 47 (delta 17), pack-reused 232 (from 2)\u001b[K\n",
      "Receiving objects: 100% (303/303), 99.69 MiB | 34.77 MiB/s, done.\n",
      "Resolving deltas: 100% (172/172), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.1.1\n",
      "Requirement already satisfied: albumentations==2.0.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.0.5)\n",
      "Collecting optuna==4.2.1 (from -r requirements.txt (line 2))\n",
      "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting huggingface-hub==0.30.2 (from -r requirements.txt (line 3))\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting lmdb==1.6.2 (from -r requirements.txt (line 4))\n",
      "  Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: opencv-python==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.11.0.86)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: torchmetrics==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.7.1)\n",
      "Collecting joblib==1.4.2 (from -r requirements.txt (line 9))\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.21.0+cu124)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 1)) (1.15.2)\n",
      "Collecting scipy>=1.10.0 (from albumentations==2.0.5->-r requirements.txt (line 1))\n",
      "  Downloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 1)) (2.11.4)\n",
      "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 1)) (0.0.23)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.5->-r requirements.txt (line 1)) (4.11.0.86)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 2)) (1.15.2)\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 2)) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna==4.2.1->-r requirements.txt (line 2)) (2.0.40)\n",
      "Collecting sqlalchemy>=1.4.2 (from optuna==4.2.1->-r requirements.txt (line 2))\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 3)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 3)) (2025.3.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.30.2->-r requirements.txt (line 3)) (4.13.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (1.3.8)\n",
      "Collecting mkl_fft (from numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading mkl_fft-1.3.14-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (1.2.4)\n",
      "Collecting mkl_random (from numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (0.1.1)\n",
      "Collecting mkl_umath (from numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.26.4->-r requirements.txt (line 7)) (2.4.1)\n",
      "Collecting mkl-service (from numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.7.1->-r requirements.txt (line 8)) (0.14.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->-r requirements.txt (line 10))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->-r requirements.txt (line 10)) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.21.0->-r requirements.txt (line 11)) (11.1.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.21.0->-r requirements.txt (line 11))\n",
      "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 1)) (3.12.3)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 1))\n",
      "  Downloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.5->-r requirements.txt (line 1)) (6.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.6.0->-r requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna==4.2.1->-r requirements.txt (line 2)) (1.3.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 8)) (75.2.0)\n",
      "Collecting setuptools (from lightning-utilities>=0.8.0->torchmetrics==1.7.1->-r requirements.txt (line 8))\n",
      "  Downloading setuptools-80.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 1)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.5->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 2)) (3.1.1)\n",
      "Collecting greenlet>=1 (from sqlalchemy>=1.4.2->optuna==4.2.1->-r requirements.txt (line 2))\n",
      "  Downloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.6.0->-r requirements.txt (line 10)) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 7)) (2024.2.0)\n",
      "Collecting intel-openmp<2026,>=2024 (from mkl->numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading intel_openmp-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.26.4->-r requirements.txt (line 7)) (2022.1.0)\n",
      "Collecting intel-cmplr-lib-ur==2025.1.1 (from intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading intel_cmplr_lib_ur-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: umf==0.10.* in /usr/local/lib/python3.11/dist-packages (from intel-cmplr-lib-ur==2025.1.1->intel-openmp<2026,>=2024->mkl->numpy==1.26.4->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.26.4->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 7)) (2024.2.0)\n",
      "Collecting intel-cmplr-lib-rt (from mkl_umath->numpy==1.26.4->-r requirements.txt (line 7))\n",
      "  Downloading intel_cmplr_lib_rt-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub==0.30.2->-r requirements.txt (line 3)) (2025.4.26)\n",
      "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading lmdb-1.6.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (297 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.15.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlalchemy-2.0.41-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.2.2-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading stringzilla-3.12.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Downloading intel_openmp-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl (48.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.6/48.6 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading intel_cmplr_lib_ur-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mkl_fft-1.3.14-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_random-1.2.10-0-cp311-cp311-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mkl_service-2.4.2-0-cp311-cp311-manylinux_2_28_x86_64.whl (77 kB)\n",
      "Downloading mkl_umath-0.1.5-0-cp311-cp311-manylinux_2_28_x86_64.whl (441 kB)\n",
      "Downloading intel_cmplr_lib_rt-2025.1.1-py2.py3-none-manylinux_2_28_x86_64.whl (47.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading setuptools-80.7.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: stringzilla, lmdb, intel-cmplr-lib-rt, setuptools, pillow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, joblib, greenlet, sqlalchemy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, intel-cmplr-lib-ur, huggingface-hub, nvidia-cusolver-cu12, intel-openmp, mkl-service, mkl_umath, mkl_random, mkl_fft, scipy, optuna\n",
      "\u001b[2K  Attempting uninstall: stringzilla\n",
      "\u001b[2K    Found existing installation: stringzilla 3.12.3\n",
      "\u001b[2K    Uninstalling stringzilla-3.12.3:\n",
      "\u001b[2K      Successfully uninstalled stringzilla-3.12.3[0m \u001b[32m 0/24\u001b[0m [stringzilla]\n",
      "\u001b[2K  Attempting uninstall: intel-cmplr-lib-rt━━\u001b[0m \u001b[32m 0/24\u001b[0m [stringzilla]\n",
      "\u001b[2K    Found existing installation: intel-cmplr-lib-rt 2024.2.0[0m [stringzilla]\n",
      "\u001b[2K    Uninstalling intel-cmplr-lib-rt-2024.2.0:[0m \u001b[32m 0/24\u001b[0m [stringzilla]\n",
      "\u001b[2K      Successfully uninstalled intel-cmplr-lib-rt-2024.2.0━━━━━━━━\u001b[0m \u001b[32m 2/24\u001b[0m [intel-cmplr-lib-rt]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/24\u001b[0m [intel-cmplr-lib-rt]\n",
      "\u001b[2K    Found existing installation: setuptools 75.2.0━━━━━━━━━━━━\u001b[0m \u001b[32m 2/24\u001b[0m [intel-cmplr-lib-rt]\n",
      "\u001b[2K    Uninstalling setuptools-75.2.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/24\u001b[0m [intel-cmplr-lib-rt]\n",
      "\u001b[2K      Successfully uninstalled setuptools-75.2.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/24\u001b[0m [setuptools]-rt]\n",
      "\u001b[2K  Attempting uninstall: pillow0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/24\u001b[0m [setuptools]\n",
      "\u001b[2K    Found existing installation: pillow 11.1.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/24\u001b[0m [setuptools]\n",
      "\u001b[2K    Uninstalling pillow-11.1.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/24\u001b[0m [setuptools]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.1.0━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\u001b[0m \u001b[32m 4/24\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.9.41:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/24\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41━━━━━━\u001b[0m \u001b[32m 5/24\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/24\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.10.19\u001b[0m \u001b[32m 5/24\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.10.19:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/24\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.10.19━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.4.0.6━━━\u001b[0m \u001b[32m 6/24\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.4.0.6:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6━━━━━━━━━\u001b[0m \u001b[32m 7/24\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/24\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.9.0.13━\u001b[0m \u001b[32m 7/24\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.9.0.13:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/24\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13━━━━━━━\u001b[0m \u001b[32m 8/24\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: joblib╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/24\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: joblib 1.5.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/24\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling joblib-1.5.0:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/24\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled joblib-1.5.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [joblib]as-cu12]\n",
      "\u001b[2K  Attempting uninstall: greenlet╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [joblib]\n",
      "\u001b[2K    Found existing installation: greenlet 3.1.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [joblib]\n",
      "\u001b[2K    Uninstalling greenlet-3.1.1:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [joblib]\n",
      "\u001b[2K      Successfully uninstalled greenlet-3.1.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [joblib]\n",
      "\u001b[2K  Attempting uninstall: sqlalchemy\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/24\u001b[0m [greenlet]\n",
      "\u001b[2K    Found existing installation: SQLAlchemy 2.0.40━━━━━━━━━━━━\u001b[0m \u001b[32m10/24\u001b[0m [greenlet]\n",
      "\u001b[2K    Uninstalling SQLAlchemy-2.0.40:[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/24\u001b[0m [greenlet]\n",
      "\u001b[2K      Successfully uninstalled SQLAlchemy-2.0.40━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/24\u001b[0m [sqlalchemy]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/24\u001b[0m [sqlalchemy]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.9.5━━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.9.5:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5━━━━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/24\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━━━━━\u001b[0m \u001b[32m13/24\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: intel-cmplr-lib-urm\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/24\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: intel-cmplr-lib-ur 2024.2.0━━\u001b[0m \u001b[32m13/24\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling intel-cmplr-lib-ur-2024.2.0:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/24\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled intel-cmplr-lib-ur-2024.2.0━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [intel-cmplr-lib-ur]\n",
      "\u001b[2K  Attempting uninstall: huggingface-hubm╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [intel-cmplr-lib-ur]\n",
      "\u001b[2K    Found existing installation: huggingface-hub 0.31.1━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [intel-cmplr-lib-ur]\n",
      "\u001b[2K    Uninstalling huggingface-hub-0.31.1:m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [intel-cmplr-lib-ur]\n",
      "\u001b[2K      Successfully uninstalled huggingface-hub-0.31.1━━━━━━━━━━━━━\u001b[0m \u001b[32m15/24\u001b[0m [huggingface-hub]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/24\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.4.40[0m \u001b[32m15/24\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.4.40:━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/24\u001b[0m [huggingface-hub]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: intel-openmp0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: intel-openmp 2024.2.0━━━━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K    Uninstalling intel-openmp-2024.2.0:╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m16/24\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K      Successfully uninstalled intel-openmp-2024.2.090m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]u12]\n",
      "\u001b[2K  Attempting uninstall: mkl-service━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Found existing installation: mkl-service 2.4.1m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Uninstalling mkl-service-2.4.1:m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K      Successfully uninstalled mkl-service-2.4.190m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K  Attempting uninstall: mkl_umath[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Found existing installation: mkl-umath 0.1.190m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Uninstalling mkl-umath-0.1.1:[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K      Successfully uninstalled mkl-umath-0.1.1\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K  Attempting uninstall: mkl_random0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Found existing installation: mkl-random 1.2.40m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K    Uninstalling mkl-random-1.2.4:0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m17/24\u001b[0m [intel-openmp]\n",
      "\u001b[2K      Successfully uninstalled mkl-random-1.2.490m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [mkl_random]\n",
      "\u001b[2K  Attempting uninstall: mkl_fft━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [mkl_random]\n",
      "\u001b[2K    Found existing installation: mkl-fft 1.3.8╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [mkl_random]\n",
      "\u001b[2K    Uninstalling mkl-fft-1.3.8:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [mkl_random]\n",
      "\u001b[2K      Successfully uninstalled mkl-fft-1.3.80m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [mkl_random]\n",
      "\u001b[2K  Attempting uninstall: scipy━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m21/24\u001b[0m [mkl_fft]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.290m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m21/24\u001b[0m [mkl_fft]\n",
      "\u001b[2K    Uninstalling scipy-1.15.2:━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.2━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: optuna━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: optuna 4.3.0[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling optuna-4.3.0:━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled optuna-4.3.0━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m23/24\u001b[0m [optuna]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [optuna]23/24\u001b[0m [optuna]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "preprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed greenlet-3.2.2 huggingface-hub-0.30.2 intel-cmplr-lib-rt-2025.1.1 intel-cmplr-lib-ur-2025.1.1 intel-openmp-2025.1.1 joblib-1.4.2 lmdb-1.6.2 mkl-service-2.4.2 mkl_fft-1.3.14 mkl_random-1.2.10 mkl_umath-0.1.5 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.2.1 pillow-11.2.1 scipy-1.15.3 setuptools-80.7.1 sqlalchemy-2.0.41 stringzilla-3.12.5\n"
     ]
    }
   ],
   "source": [
    "# clone the ADIS repository\n",
    "!git clone https://github.com/sathishkumar67/SSD_MobileNetV3_ADIS.git\n",
    "# move the files to the current directory\n",
    "!mv /kaggle/working/SSD_MobileNetV3_ADIS/* /kaggle/working/\n",
    "# upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# install the required packages\n",
    "!pip install  -r requirements.txt --upgrade --upgrade-strategy eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9871aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import optuna\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "from ssdlite_mobnetv3_adis.utils import unzip_file, replace_activation_function\n",
    "from ssdlite_mobnetv3_adis.dataset import collate_fn, SSDLITEOBJDET_DATASET, CachedSSDLITEOBJDET_DATASET\n",
    "from ssdlite_mobnetv3_adis.model import SSDLITE_MOBILENET_V3_Large\n",
    "from ssdlite_mobnetv3_adis.epu import EPU\n",
    "\n",
    "\n",
    "# set random seed for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd607711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dea5ee7e8d482a86c7b25e7b2d4917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "balanced_dataset.zip:   0%|          | 0.00/7.04G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unzipping:  46%|████▋     | 3.27G/7.07G [00:20<00:23, 160MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75/1522063613.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# download the dataset and unzip it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPO_ID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFILENAME_IN_REPO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPO_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0munzip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOCAL_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kaggle/working/ssdlite_mobnetv3_adis/utils.py\u001b[0m in \u001b[0;36munzip_file\u001b[0;34m(zip_path, target_dir)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mzinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Extract the file or directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# Update progress bar by the file's uncompressed size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mextract\u001b[0;34m(self, member, path, pwd)\u001b[0m\n\u001b[1;32m   1683\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[0;34m(fsrc, fdst, length)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eof\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_read1\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mZIP_DEFLATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_READ_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             self._eof = (self._decompressor.eof or\n\u001b[1;32m   1044\u001b[0m                          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compress_left\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set constants\n",
    "REPO_ID = \"pt-sk/ADIS\" \n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"                       \n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake'] \n",
    "NUM_CLASSES = len(CLASSES)\n",
    "NUM_CLASSES_WITH_BG = NUM_CLASSES + 1    # 1 for background class\n",
    "\n",
    "# download the dataset and unzip it\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db86b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/train_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9532/18139 [02:03<06:59, 20.50it/s] libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 18139/18139 [03:36<00:00, 83.78it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/val_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2390/2390 [00:27<00:00, 86.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset and caching to /kaggle/working/balanced_dataset/test_cache...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1743/2390 [00:22<00:04, 150.43it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|██████████| 2390/2390 [00:30<00:00, 78.10it/s] \n"
     ]
    }
   ],
   "source": [
    "# set pin memory device\n",
    "PIN_MEMORY_DEVICE = \"cuda:0\"\n",
    "NUM_CORES = os.cpu_count()\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# prepare the dataset\n",
    "train_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"train\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"val\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"test\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "\n",
    "# samplers for reproducibility\n",
    "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "val_sampler = RandomSampler(val_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "test_sampler = RandomSampler(test_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "\n",
    "# prepare the dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=test_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526c5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bohb_tunner(\n",
    "    args: dict,\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    dataloaders: dict[str, torch.utils.data.DataLoader],\n",
    "    callback\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train an object detection model with linear warmup, cosine decay, EMA, and early stopping on val loss.\n",
    "\n",
    "    Args:\n",
    "        args (dict): Dictionary containing training parameters:\n",
    "            - device (torch.device): Device to train on (e.g., 'cuda' or 'cpu').\n",
    "            - warmup_epochs (int): Number of epochs for linear warmup.\n",
    "            - num_epochs (int): Total number of epochs for training.\n",
    "            - patience (int): Early stopping patience in epochs (val loss based).\n",
    "            - initial_lr (float): Initial learning rate.\n",
    "            - lr_factor (float): Factor to reduce learning rate.\n",
    "            - start_factor (float): Start factor for linear warmup.\n",
    "            - end_factor (float): End factor for linear warmup.\n",
    "        model (nn.Module): The detection model.\n",
    "        optimizer (optim.Optimizer): Optimizer instance.\n",
    "        dataloaders (dict): Dict with 'train' and 'val' DataLoader.\n",
    "        callback (Callable): Callback function for BOHB.\n",
    "    \"\"\"\n",
    "    # Unpack dataloaders\n",
    "    train_loader, val_loader = dataloaders['train'], dataloaders['val']\n",
    "\n",
    "    # Set up LR schedulers: linear warmup then cosine annealing\n",
    "    scheduler_warmup = LinearLR(optimizer, start_factor=args[\"start_factor\"], end_factor=args[\"end_factor\"], total_iters=args[\"warmup_epochs\"])\n",
    "    scheduler_cosine = CosineAnnealingLR(optimizer, T_max=(args[\"num_epochs\"] - args[\"warmup_epochs\"]), eta_min=args[\"initial_lr\"] * args[\"lr_factor\"])\n",
    "    # SequentialLR to combine warmup and cosine annealing\n",
    "    scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_cosine], milestones=[args[\"warmup_epochs\"]])\n",
    "\n",
    "    # Initialize best validation loss and patience counter\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, args[\"num_epochs\"] + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        # Initialize total loss for the epoch\n",
    "        total_loss = 0.0\n",
    "        # Create a tqdm progress bar for training\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{args['num_epochs']}\", unit=\"batch\")\n",
    "        for images, targets in train_bar:\n",
    "            # Move images to device\n",
    "            images = images.to(args[\"device\"])\n",
    "            # Move targets to device\n",
    "            targets = [{k: v.to(args[\"device\"]) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Forward pass and compute loss\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            total_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "        # Step scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation\n",
    "        total_val_loss = 0.0\n",
    "        # no gradient calculation for validation\n",
    "        with torch.no_grad():\n",
    "            # Create a tqdm progress bar for validation\n",
    "            for images, targets in tqdm(val_loader, desc=\"Validating\", unit=\"batch\"):\n",
    "                # Move images to device\n",
    "                images = images.to(args[\"device\"])\n",
    "                # Move targets to device\n",
    "                targets = [{k: v.to(args[\"device\"]) for k, v in t.items()} for t in targets]\n",
    "                # Forward pass and compute loss\n",
    "                loss_dict = model(images, targets)\n",
    "                # Accumulate validation loss\n",
    "                total_val_loss += sum(loss for loss in loss_dict.values()).item()\n",
    "                \n",
    "        # Calculate average validation loss\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        \n",
    "        # report the average validation loss to the BOHB callback\n",
    "        callback(avg_val_loss, epoch)\n",
    "\n",
    "        # Print training and validation loss\n",
    "        print(f\"Epoch {epoch}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping on val loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= args[\"patience\"]:\n",
    "                print(f\"Early stopping at epoch {epoch} (no improvement for {args['patience']} epochs)\")\n",
    "                break\n",
    "    \n",
    "    # return the best validation loss\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525cb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_EPOCHS = 10\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "END_FACTOR = 1.0\n",
    "\n",
    "# define the objective function\n",
    "def objective(trial):\n",
    "    # define callback to report intermidiate results\n",
    "    def on_train_epoch_end(score, epoch):\n",
    "        trial.report(score, step=epoch)  \n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "        \n",
    "    # suggest hyperparameters for the model\n",
    "    INITIAL_LR = trial.suggest_float(\"INITIAL_LR\", 1e-4, 1e-1, log=True)\n",
    "    LR_FACTOR = trial.suggest_float(\"LR_FACTOR\", 1e-4, 1e-1, log=True)\n",
    "    START_FACTOR = trial.suggest_float(\"START_FACTOR\", 1e-4, 1e-1, log=True)\n",
    "    WEIGHT_DECAY = trial.suggest_float(\"WEIGHT_DECAY\", 1e-4, 1e-1, log=True)\n",
    "    MOMENTUM = trial.suggest_float(\"MOMENTUM\", 0.7, 0.99)\n",
    "    \n",
    "    # create the model\n",
    "    model = SSDLITE_MOBILENET_V3_Large(num_classes_with_bg=NUM_CLASSES_WITH_BG)\n",
    "    # replace the activation function with epu\n",
    "    epu_activation_fn = EPU()\n",
    "    replace_activation_function(model, epu_activation_fn)\n",
    "    # move the model to device\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # create the optimizer\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=INITIAL_LR,\n",
    "        betas=(MOMENTUM, 0.999),\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        eps=1e-8,\n",
    "        fused=True\n",
    "    )\n",
    "    \n",
    "    # tune the model\n",
    "    best_val_loss = bohb_tunner(\n",
    "        args={\n",
    "            \"device\": DEVICE,\n",
    "            \"warmup_epochs\": WARMUP_EPOCHS,\n",
    "            \"num_epochs\": NUM_EPOCHS,\n",
    "            \"patience\": PATIENCE,\n",
    "            \"initial_lr\": INITIAL_LR,\n",
    "            \"lr_factor\": LR_FACTOR,\n",
    "            \"start_factor\": START_FACTOR,\n",
    "            \"end_factor\": END_FACTOR\n",
    "        },\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        dataloaders={\"train\":train_loader, \"val\":val_loader},\n",
    "        callback=on_train_epoch_end\n",
    "    )\n",
    "    # return the best validation loss\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b10571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 08:01:37,501] A new study created in memory with name: ssd_mobnetv3_adis_epu_bohbtune\n",
      "Downloading: \"https://download.pytorch.org/models/ssdlite320_mobilenet_v3_large_coco-a79551df.pth\" to /root/.cache/torch/hub/checkpoints/ssdlite320_mobilenet_v3_large_coco-a79551df.pth\n",
      "100%|██████████| 13.4M/13.4M [00:00<00:00, 201MB/s]\n",
      "Epoch 1/50: 100%|██████████| 284/284 [02:23<00:00,  1.98batch/s, loss=18.8, lr=9.48e-8]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.52batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=18.8128, Val Loss=18.7341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 284/284 [02:20<00:00,  2.03batch/s, loss=5.02, lr=0.000117]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss=6.5411, Val Loss=5.3463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=5.04, lr=0.000233]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss=4.9229, Val Loss=4.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 284/284 [02:19<00:00,  2.03batch/s, loss=3.64, lr=0.000349]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss=4.1921, Val Loss=4.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 284/284 [02:20<00:00,  2.02batch/s, loss=3.43, lr=0.000466]\n",
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.64batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss=3.6240, Val Loss=3.6525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 284/284 [02:19<00:00,  2.03batch/s, loss=2.68, lr=0.000582]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss=3.2531, Val Loss=3.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=3.27, lr=0.000582]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss=2.9106, Val Loss=3.3584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 284/284 [02:18<00:00,  2.05batch/s, loss=2.67, lr=0.00058]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss=2.6422, Val Loss=3.3122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=1.88, lr=0.000576]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss=2.4640, Val Loss=3.2487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=2.53, lr=0.000571]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss=2.2659, Val Loss=3.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=1.81, lr=0.000565]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss=2.0962, Val Loss=3.2481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=1.87, lr=0.000557]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.57batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss=1.9652, Val Loss=3.3271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=2.02, lr=0.000549]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.58batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss=1.8452, Val Loss=3.3426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 284/284 [02:19<00:00,  2.03batch/s, loss=1.7, lr=0.000539] \n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss=1.7274, Val Loss=3.4523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 284/284 [02:18<00:00,  2.05batch/s, loss=1.98, lr=0.000527]\n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss=1.5984, Val Loss=3.5069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 284/284 [02:19<00:00,  2.04batch/s, loss=1.8, lr=0.000515] \n",
      "Validating: 100%|██████████| 38/38 [00:10<00:00,  3.65batch/s]\n",
      "[I 2025-05-15 08:41:43,746] Trial 0 finished with value: 3.2481229869942916 and parameters: {'INITIAL_LR': 0.0005824283135055773, 'LR_FACTOR': 0.00940428043364665, 'START_FACTOR': 0.0001627105524931517, 'WEIGHT_DECAY': 0.001021068178450286, 'MOMENTUM': 0.78397802624776}. Best is trial 0 with value: 3.2481229869942916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss=1.5051, Val Loss=3.6535\n",
      "Early stopping at epoch 16 (no improvement for 5 epochs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:  38%|███▊      | 107/284 [00:54<01:29,  1.98batch/s, loss=6.39, lr=0.000823]\n",
      "[W 2025-05-15 08:42:38,025] Trial 1 failed with parameters: {'INITIAL_LR': 0.08286585374783254, 'LR_FACTOR': 0.07949185602592693, 'START_FACTOR': 0.00993766831573112, 'WEIGHT_DECAY': 0.049146756073796136, 'MOMENTUM': 0.976817165212368} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_75/1394800244.py\", line 42, in objective\n",
      "    best_val_loss = bohb_tunner(\n",
      "                    ^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_75/2640974943.py\", line 63, in bohb_tunner\n",
      "    total_loss += loss.item()\n",
      "                  ^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-15 08:42:38,027] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75/911429288.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Optimize with a callback to stop after NUM_TRIALS complete trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_TRIALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# save the study\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     ):\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_75/1394800244.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# tune the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     best_val_loss = bohb_tunner(\n\u001b[0m\u001b[1;32m     43\u001b[0m         args={\n\u001b[1;32m     44\u001b[0m             \u001b[0;34m\"device\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDEVICE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_75/2640974943.py\u001b[0m in \u001b[0;36mbohb_tunner\u001b[0;34m(args, model, optimizer, dataloaders, callback)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;31m# Accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mtrain_bar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define the number of trials\n",
    "NUM_TRIALS = 2\n",
    "\n",
    "# load the study\n",
    "study = optuna.create_study(direction='minimize', \n",
    "                            sampler=optuna.samplers.TPESampler(), \n",
    "                            pruner=optuna.pruners.HyperbandPruner(),\n",
    "                            study_name=\"ssd_mobnetv3_adis_epu_bohbtune\",\n",
    "                            load_if_exists=True)\n",
    "\n",
    "# Optimize with a callback to stop after NUM_TRIALS complete trials\n",
    "study.optimize(objective, n_trials=NUM_TRIALS)\n",
    "\n",
    "# save the study\n",
    "joblib.dump(study, f\"{LOCAL_DIR}/ssd_mobnetv3_adis_epu_bohbtune_study1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500347e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
