{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ea30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T03:57:32.376938Z",
     "iopub.status.busy": "2025-05-18T03:57:32.376677Z",
     "iopub.status.idle": "2025-05-18T03:59:35.164101Z",
     "shell.execute_reply": "2025-05-18T03:59:35.163095Z"
    },
    "papermill": {
     "duration": 122.792333,
     "end_time": "2025-05-18T03:59:35.165781",
     "exception": false,
     "start_time": "2025-05-18T03:57:32.373448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell downloads repository utilities and installs dependencies.\n",
    "# It's intended for ephemeral notebook environments (Colab / Kaggle).\n",
    "# If running locally you can skip the git clone/move steps and use the local files directly.\n",
    "# Clone the ADIS helper repository (contains model & training code).\n",
    "!git clone https://github.com/sathishkumar67/SSD_MobileNetV3_ADIS.git\n",
    "# On some hosted runtimes the repo contents may need moving to the working directory.\n",
    "# The following mv command was used for Kaggle examples; remove or adapt it on other platforms.\n",
    "!mv /kaggle/working/SSD_MobileNetV3_ADIS/* /kaggle/working/  # adapt to your environment if needed\n",
    "# Ensure pip is up-to-date then install required python packages from requirements.txt.\n",
    "!pip install --upgrade pip\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb41a43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T03:59:35.226481Z",
     "iopub.status.busy": "2025-05-18T03:59:35.225748Z",
     "iopub.status.idle": "2025-05-18T03:59:44.291381Z",
     "shell.execute_reply": "2025-05-18T03:59:44.290748Z"
    },
    "papermill": {
     "duration": 9.096987,
     "end_time": "2025-05-18T03:59:44.292777",
     "exception": false,
     "start_time": "2025-05-18T03:59:35.195790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core imports and reproducibility setup\n",
    "import os\n",
    "import optuna\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR, SequentialLR\n",
    "# Utilities and model components from the ADIS helper package\n",
    "from ssdlite_mobnetv3_adis.utils import unzip_file, replace_activation_function\n",
    "from ssdlite_mobnetv3_adis.dataset import collate_fn, SSDLITEOBJDET_DATASET, CachedSSDLITEOBJDET_DATASET\n",
    "from ssdlite_mobnetv3_adis.model import SSDLITE_MOBILENET_V3_Large\n",
    "from ssdlite_mobnetv3_adis.epu import EPU\n",
    "\n",
    "# Set random seed for reproducibility across runs and devices.\n",
    "# NOTE: Complete determinism in CUDA may not be achievable across different drivers/hardware.\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a5782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T03:59:44.351590Z",
     "iopub.status.busy": "2025-05-18T03:59:44.350849Z",
     "iopub.status.idle": "2025-05-18T04:01:59.101477Z",
     "shell.execute_reply": "2025-05-18T04:01:59.100518Z"
    },
    "papermill": {
     "duration": 134.780866,
     "end_time": "2025-05-18T04:01:59.102668",
     "exception": false,
     "start_time": "2025-05-18T03:59:44.321802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataset constants and download\n",
    "# REPO_ID points to a Hugging Face dataset repo containing a zipped dataset named balanced_dataset.zip\n",
    "REPO_ID = \"pt-sk/ADIS\"\n",
    "DATASET_NAME = \"balanced_dataset\"\n",
    "REPO_TYPE = \"dataset\"\n",
    "FILENAME_IN_REPO = f\"{DATASET_NAME}.zip\"\n",
    "LOCAL_DIR = os.getcwd()\n",
    "DATASET_PATH = f\"{LOCAL_DIR}/{FILENAME_IN_REPO}\"\n",
    "DATASET_FOLDER_PATH = f\"{LOCAL_DIR}/{DATASET_NAME}\"\n",
    "# Class names for the dataset (no background class here)\n",
    "CLASSES = ['Cat', 'Cattle', 'Chicken', 'Deer', 'Dog', 'Squirrel', 'Eagle', 'Goat', 'Rodents', 'Snake']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "NUM_CLASSES_WITH_BG = NUM_CLASSES + 1  # add 1 for the background class used by SSD\n",
    "\n",
    "# Download the dataset archive and extract it locally. If already present, hf_hub_download will reuse the file.\n",
    "hf_hub_download(repo_id=REPO_ID, filename=FILENAME_IN_REPO, repo_type=REPO_TYPE, local_dir=LOCAL_DIR)\n",
    "unzip_file(DATASET_PATH, LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61d37c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:01:59.193949Z",
     "iopub.status.busy": "2025-05-18T04:01:59.193659Z",
     "iopub.status.idle": "2025-05-18T04:07:14.433505Z",
     "shell.execute_reply": "2025-05-18T04:07:14.432793Z"
    },
    "papermill": {
     "duration": 315.286684,
     "end_time": "2025-05-18T04:07:14.434943",
     "exception": false,
     "start_time": "2025-05-18T04:01:59.148259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader setup: configure device pinning, parallel workers and construct datasets/dataloaders\n",
    "# pin_memory_device is used by DataLoader to place tensors on the correct cuda device when pinning is enabled.\n",
    "PIN_MEMORY_DEVICE = \"cuda:0\"\n",
    "NUM_CORES = os.cpu_count()\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Build cached dataset wrappers for faster access during tuning/training\n",
    "train_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"train\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "val_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"val\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "test_dataset = CachedSSDLITEOBJDET_DATASET(\n",
    "    dataset_class=SSDLITEOBJDET_DATASET,\n",
    "    root_dir=DATASET_FOLDER_PATH,\n",
    "    split=\"test\",\n",
    "    num_classes=NUM_CLASSES_WITH_BG)\n",
    "\n",
    "# Use RandomSampler with a fixed generator seed for deterministic sampling order across runs\n",
    "train_sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "val_sampler = RandomSampler(val_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "test_sampler = RandomSampler(test_dataset, generator=torch.Generator().manual_seed(RANDOM_SEED))\n",
    "\n",
    "# Create dataloaders. persistent_workers=True can improve throughput but requires careful worker resource management.\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sampler=test_sampler,\n",
    "    num_workers=NUM_CORES,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    "    pin_memory_device=PIN_MEMORY_DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5c878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:07:14.678179Z",
     "iopub.status.busy": "2025-05-18T04:07:14.677876Z",
     "iopub.status.idle": "2025-05-18T04:07:14.688571Z",
     "shell.execute_reply": "2025-05-18T04:07:14.687836Z"
    },
    "papermill": {
     "duration": 0.134066,
     "end_time": "2025-05-18T04:07:14.689778",
     "exception": false,
     "start_time": "2025-05-18T04:07:14.555712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bohb_tunner(\n",
    "    args: dict,\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    dataloaders: dict[str, torch.utils.data.DataLoader],\n",
    "    callback,\n",
    ") -> float:\n",
    "    \"\"\"Train helper used by the Optuna/BOHB objective.\n",
    "\n",
    "    This function runs a full training loop for a single trial using a two-stage scheduler:\n",
    "    1) Linear warmup for `warmup_epochs` iterations (LinearLR)\n",
    "    2) Cosine annealing for the remaining epochs (CosineAnnealingLR)\n",
    "\n",
    "    The function reports the epoch-level validation loss via the provided `callback` and returns\n",
    "    the best observed validation loss for the trial (lower is better).\n",
    "\n",
    "    Args:\n",
    "        args: configuration dict with keys `device`, `warmup_epochs`, `num_epochs`, `patience`,\n",
    "              `initial_lr`, `lr_factor`, `start_factor`, and `end_factor`.\n",
    "        model: a PyTorch nn.Module implementing the SSD-style forward(images, targets) -> loss_dict API.\n",
    "        optimizer: optimizer instance (e.g., AdamW) already constructed for the model.\n",
    "        dataloaders: dict containing the 'train' and 'val' DataLoader objects.\n",
    "        callback: callable(callback_score, epoch) used to report intermediate results (Optuna).\n",
    "\n",
    "    Returns:\n",
    "        float: best validation loss observed during training (lower is better).\n",
    "    \"\"\"\n",
    "    # Unpack dataloaders\n",
    "    train_loader, val_loader = dataloaders['train'], dataloaders['val']\n",
    "\n",
    "    # Build the two-phase scheduler: linear warmup -> cosine annealing\n",
    "    scheduler_warmup = LinearLR(optimizer, start_factor=args[\"start_factor\"], end_factor=args[\"end_factor\"], total_iters=args[\"warmup_epochs\"])\n",
    "    scheduler_cosine = CosineAnnealingLR(optimizer, T_max=(args[\"num_epochs\"] - args[\"warmup_epochs\"]), eta_min=args[\"initial_lr\"] * args[\"lr_factor\"])\n",
    "    scheduler = SequentialLR(optimizer, schedulers=[scheduler_warmup, scheduler_cosine], milestones=[args[\"warmup_epochs\"]])\n",
    "\n",
    "    # Early stopping bookkeeping\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Training loop over epochs\n",
    "    for epoch in range(1, args[\"num_epochs\"] + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{args['num_epochs']}\", unit=\"batch\")\n",
    "        for images, targets in train_bar:\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(args[\"device\"])\n",
    "            targets = [{k: v.to(args[\"device\"]) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Forward: model returns a dict of losses (SSD-style). Sum to scalar loss for backward.\n",
    "            loss_dict = model(images, targets)\n",
    "            loss = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backpropagation step\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=loss.item(), lr=optimizer.param_groups[0]['lr'])\n",
    "\n",
    "        avg_train_loss = total_loss / max(1, len(train_loader))\n",
    "\n",
    "        # Advance the LR scheduler by one epoch\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation: evaluate without gradient calculations\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, targets in tqdm(val_loader, desc=\"Validating\", unit=\"batch\"):\n",
    "                images = images.to(args[\"device\"])\n",
    "                targets = [{k: v.to(args[\"device\"]) for k, v in t.items()} for t in targets]\n",
    "                loss_dict = model(images, targets)\n",
    "                total_val_loss += sum(loss for loss in loss_dict.values()).item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / max(1, len(val_loader))\n",
    "\n",
    "        # Report the validation loss back to the hyperparameter tuner\n",
    "        callback(avg_val_loss, epoch)\n",
    "\n",
    "        print(f\"Epoch {epoch}: Train Loss={avg_train_loss:.4f}, Val Loss={avg_val_loss:.4f}\")\n",
    "\n",
    "        # Early stopping on validation loss\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= args[\"patience\"]:\n",
    "                print(f\"Early stopping at epoch {epoch} (no improvement for {args['patience']} epochs)\")\n",
    "                break\n",
    "\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d61fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:07:14.982653Z",
     "iopub.status.busy": "2025-05-18T04:07:14.982372Z",
     "iopub.status.idle": "2025-05-18T04:07:15.065079Z",
     "shell.execute_reply": "2025-05-18T04:07:15.064350Z"
    },
    "papermill": {
     "duration": 0.203292,
     "end_time": "2025-05-18T04:07:15.066322",
     "exception": false,
     "start_time": "2025-05-18T04:07:14.863030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Optuna/BOHB tuning constants and objective function\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_EPOCHS = 10\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "END_FACTOR = 1.0\n",
    "\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna tuning. This function is executed for each trial and should\n",
    "    return a scalar value to minimize (here: validation loss).\n",
    "\"\"\"\n",
    "    def on_train_epoch_end(score, epoch):\n",
    "        # report intermediate score to the trial (used by pruning handlers)\n",
    "        trial.report(score, step=epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    # Suggest hyperparameters to search over. Use log sampling for scale-sensitive params.\n",
    "    INITIAL_LR = trial.suggest_float(\"INITIAL_LR\", 1e-4, 1e-1, log=True)\n",
    "    LR_FACTOR = trial.suggest_float(\"LR_FACTOR\", 1e-4, 1e-1, log=True)\n",
    "    START_FACTOR = trial.suggest_float(\"START_FACTOR\", 1e-4, 1e-1, log=True)\n",
    "    WEIGHT_DECAY = trial.suggest_float(\"WEIGHT_DECAY\", 1e-6, 1e-1, log=True)\n",
    "    MOMENTUM = trial.suggest_float(\"MOMENTUM\", 0.7, 0.99)\n",
    "\n",
    "    # Build model, replace activation with EPU (efficient parametric unit) and move to device\n",
    "    model = SSDLITE_MOBILENET_V3_Large(num_classes_with_bg=NUM_CLASSES_WITH_BG)\n",
    "    epu_activation_fn = EPU()\n",
    "    replace_activation_function(model, epu_activation_fn)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Create optimizer for this trial's hyperparameters\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=INITIAL_LR,\n",
    "        betas=(MOMENTUM, 0.999),\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        eps=1e-8,\n",
    "        fused=True\n",
    "    )\n",
    "\n",
    "    # Run the tuning loop and return the best validation loss observed\n",
    "    best_val_loss = bohb_tunner(\n",
    "        args={\n",
    "            \"device\": DEVICE,\n",
    "            \"warmup_epochs\": WARMUP_EPOCHS,\n",
    "            \"num_epochs\": NUM_EPOCHS,\n",
    "            \"patience\": PATIENCE,\n",
    "            \"initial_lr\": INITIAL_LR,\n",
    "            \"lr_factor\": LR_FACTOR,\n",
    "            \"start_factor\": START_FACTOR,\n",
    "            \"end_factor\": END_FACTOR\n",
    "        },\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        dataloaders={\"train\": train_loader, \"val\": val_loader},\n",
    "        callback=on_train_epoch_end\n",
    "    )\n",
    "    return best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc4b52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-18T04:07:15.305769Z",
     "iopub.status.busy": "2025-05-18T04:07:15.305064Z",
     "iopub.status.idle": "2025-05-18T11:56:56.306532Z",
     "shell.execute_reply": "2025-05-18T11:56:56.305794Z"
    },
    "papermill": {
     "duration": 28181.119784,
     "end_time": "2025-05-18T11:56:56.307794",
     "exception": false,
     "start_time": "2025-05-18T04:07:15.188010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run hyperparameter optimization\n",
    "# Configure number of trials and create or load an existing Optuna study.\n",
    "NUM_TRIALS = 30  # adjust to your compute/time budget\n",
    "\n",
    "# If you want to resume a previous study, provide a storage URL or load the joblib dump instead.\n",
    "# study = joblib.load(\"/path/to/study.pkl\")\n",
    "# Direction should be 'minimize' for validation loss or 'maximize' for metrics like mAP\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"ssd_mobnetv3_adis_epu_bohbtune_study\")\n",
    "\n",
    "# Execute the optimization loop. This will run `objective` NUM_TRIALS times (may be parallelized with RDB storage).\n",
    "study.optimize(objective, n_trials=NUM_TRIALS)\n",
    "\n",
    "# Persist the study to disk so results can be inspected or resumed later\n",
    "joblib.dump(study, f\"{os.path.join(LOCAL_DIR, 'optuna_study.pkl')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b646826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the study from disk and inspect the best trial's parameters\n",
    "study = joblib.load(os.path.join(LOCAL_DIR, 'optuna_study.pkl'))\n",
    "# Display the best trial summary (loss, params, etc.)\n",
    "study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model using the best hyperparameters found by the study\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "WARMUP_EPOCHS = 10\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "END_FACTOR = 1.0\n",
    "# Load best hyperparameters from the Optuna study. Ensure `study` is defined or loaded above.\n",
    "INITIAL_LR = study.best_params[\"INITIAL_LR\"]\n",
    "LR_FACTOR = study.best_params[\"LR_FACTOR\"]\n",
    "START_FACTOR = study.best_params[\"START_FACTOR\"]\n",
    "WEIGHT_DECAY = study.best_params[\"WEIGHT_DECAY\"]\n",
    "MOMENTUM = study.best_params[\"MOMENTUM\"]\n",
    "\n",
    "# Instantiate and prepare model for final training\n",
    "model = SSDLITE_MOBILENET_V3_Large(num_classes_with_bg=NUM_CLASSES_WITH_BG)\n",
    "epu_activation_fn = EPU()\n",
    "replace_activation_function(model, epu_activation_fn)\n",
    "model.to(DEVICE)\n",
    "\n",
    "# Final optimizer using the selected hyperparameters\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=INITIAL_LR,\n",
    "    betas=(MOMENTUM, 0.999),\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    eps=1e-8,\n",
    "    fused=True\n",
    ")\n",
    "\n",
    "# Use the project's train function to run a full training session. The train function should accept\n",
    "# the optimizer, model, dataloaders and other configs – consult ssdlite_mobnetv3_adis.trainer for details.\n",
    "from ssdlite_mobnetv3_adis.trainer import train\n",
    "# pass the necessary arguments to train() as per its signature\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57357b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7448409,
     "sourceId": 11853761,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28786.17104,
   "end_time": "2025-05-18T11:57:14.192868",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-18T03:57:28.021828",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "208e8ba17af94fe0bca67f76d1b30b5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37f4c59074d34bfe85f7c3c49dda25ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf8388ff6d71407eb283c1551c480a92",
        "IPY_MODEL_e4ef0b11993540f48870922eb53d5cd4",
        "IPY_MODEL_a17029ee4ce14c6eb193402bc717c420"
       ],
       "layout": "IPY_MODEL_8d3e218430fd46b39a455f9775cd2ce3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4774c922c65b40ca9f0450950aba7bf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a825351525b467ebfb253e9a3442786": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78839de0a3e8490d934b33337da01a2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d3e218430fd46b39a455f9775cd2ce3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "929329f190fe44f59b24cea269feacee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a17029ee4ce14c6eb193402bc717c420": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4774c922c65b40ca9f0450950aba7bf5",
       "placeholder": "​",
       "style": "IPY_MODEL_929329f190fe44f59b24cea269feacee",
       "tabbable": null,
       "tooltip": null,
       "value": " 7.04G/7.04G [01:30&lt;00:00, 64.4MB/s]"
      }
     },
     "bf8388ff6d71407eb283c1551c480a92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_78839de0a3e8490d934b33337da01a2b",
       "placeholder": "​",
       "style": "IPY_MODEL_f331e2c2a5d54338b18d4ff8e41cc4e8",
       "tabbable": null,
       "tooltip": null,
       "value": "balanced_dataset.zip: 100%"
      }
     },
     "e4ef0b11993540f48870922eb53d5cd4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a825351525b467ebfb253e9a3442786",
       "max": 7041638232,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_208e8ba17af94fe0bca67f76d1b30b5b",
       "tabbable": null,
       "tooltip": null,
       "value": 7041638232
      }
     },
     "f331e2c2a5d54338b18d4ff8e41cc4e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
